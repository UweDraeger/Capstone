---
title: "Notes - Capstone project"
author: "Uwe Draeger"
date: "06/05/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Project Notes

Task 1 - Getting and cleaning the data
Tokenization - use the tidytext framework rather than trying to build a mini-version independently. 

Section recommends to use random sampling to build a model.
I question to usefulness of random data compared to just top 500 lines or so.
The final work will be on the complate dataset, i.e. the "population" - which is of course only a sample of the unavailable universe of all text). For constructing the tools for model building specific parameter values and their representativeness should not matter much.


There is a different approach to analyze a specific text like a book or other work  (where you focus on the relevant words - anti_join(stop_words)) compared to guessing the next word. 

Sampling:
How many lines do I need/want?


http://www.cs.cornell.edu/courses/cs4740/2014sp/lectures/smoothing+backoff.pdf
Smoothing
Unknown words
Evaluation 